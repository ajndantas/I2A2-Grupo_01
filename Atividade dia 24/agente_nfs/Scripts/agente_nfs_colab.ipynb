{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V8-k4w9Jt4yy","executionInfo":{"status":"ok","timestamp":1750312662607,"user_tz":180,"elapsed":2272,"user":{"displayName":"Antonio Dantas","userId":"09143204756506017123"}},"outputId":"4f6dbe49-66ef-409e-c6da-d93412e20819"},"id":"V8-k4w9Jt4yy","execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","execution_count":21,"id":"6a3458f4","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6737,"status":"ok","timestamp":1750312612817,"user":{"displayName":"Antonio Dantas","userId":"09143204756506017123"},"user_tz":180},"id":"6a3458f4","outputId":"f98787b5-04d6-497b-832b-c40c0a6bcbc6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (25.1.1)\n"]}],"source":["# UPGRADE DO PIP PARA VERSÃO 25.1.1 - PASSO 1\n","\n","!python -m pip install --upgrade pip\n","\n","%pip install -qqqr requirements.txt"]},{"cell_type":"markdown","id":"49b23614","metadata":{"id":"49b23614"},"source":["#### IMPORTS"]},{"cell_type":"code","execution_count":22,"id":"d3f5916e","metadata":{"id":"d3f5916e","executionInfo":{"status":"ok","timestamp":1750312612831,"user_tz":180,"elapsed":2,"user":{"displayName":"Antonio Dantas","userId":"09143204756506017123"}}},"outputs":[],"source":["from os import getenv, mkdir, listdir\n","from io import BytesIO\n","from shutil import rmtree\n","from os.path import basename,exists\n","from pathlib import Path\n","from zipfile import ZipFile\n","from re import search\n","from pandas import read_csv, read_sql\n","import sqlalchemy as sqlalc\n","from dotenv import load_dotenv\n","from langchain_core.prompts import PromptTemplate\n","from langchain_core.output_parsers import JsonOutputParser\n","from pydantic import BaseModel, Field\n","from langchain_google_genai import ChatGoogleGenerativeAI\n","\n","class SemArquivoCabecalho(Exception):\n","    pass\n","\n","class SemArquivoItens(Exception):\n","    pass\n","\n","class SemArquivoZip(Exception):\n","    pass\n","\n","class SemResposta(Exception):\n","    pass"]},{"cell_type":"markdown","id":"ea27b222","metadata":{"id":"ea27b222"},"source":["#### FUNÇÃO QUE DESCOMPACTA ARQUIVOS<br/>\n","<ul><li>VERIFICA SE EXISTE OS ARQUIVOS DE CABEÇALHO E ITENS</li></ul>\n","<ul><li>CASO ALGUM DELES NÃO EXISTA, É LANÇADA UMA EXCEÇÃO (Raise)</li></ul>\n","<ul><li>É OBRIGATÓRIO QUE OS ARQUIVOS SEJAM CSVs E TENHAM \"CABECALHO\" E \"ITENS\" NO NOME</li></ul>"]},{"cell_type":"code","execution_count":23,"id":"eb6c4842","metadata":{"id":"eb6c4842","executionInfo":{"status":"ok","timestamp":1750312612895,"user_tz":180,"elapsed":63,"user":{"displayName":"Antonio Dantas","userId":"09143204756506017123"}}},"outputs":[],"source":["def unzip(arquivo):\n","\n","\n","    #for f in arquivos_zipados:\n","    with ZipFile(arquivo, 'r') as zip_ref:\n","\n","        #zip_ref.extractall(f'{diretorio_destino}')\n","\n","        arquivos = zip_ref.namelist()\n","        #arquivos = [f'{Path(diretorio_destino) / x}' for x in listdir(f'{diretorio_destino}')]\n","\n","        print(f'Arquivos descompactados: {arquivos}')\n","\n","        # Check if any pattern matches\n","        arquivocabecalhoencontrado = any(search(r'.*[Cc]abecalho.csv$', arquivo) for arquivo in arquivos)\n","        arquivoitensencontrado = any(search(r'.*[Ii]tens.csv$', arquivo) for arquivo in arquivos)\n","\n","        if arquivocabecalhoencontrado == False:\n","            return \"SemArquivoCabecalho\"\n","\n","        elif arquivoitensencontrado == False:\n","            return \"SemArquivoItens\"\n","\n","        lista_arquivos = []\n","\n","        for arquivo in arquivos:\n","            if (search(r'.*[Cc]abecalho.csv$', arquivo) is not None):\n","                with zip_ref.open(arquivo) as myfile:\n","                    # The resulting BytesIO object can be used anywhere a file-like object is expected,\n","                    # but it operates entirely in memory, making it useful for temporary processing of\n","                    # binary data (such as images, PDFs, or ZIP files) without writing to disk.\n","                    # A common use case is when you need to manipulate or pass file data to\n","                    # APIs or libraries that expect a file-like object(Método read_csv do pandas), but you want to avoid\n","                    # filesystem I/O.\n","                    lista_arquivos.append({'cabecalho': BytesIO(myfile.read()),'nome_arquivo': arquivo})\n","\n","            elif (search(r'.*[Ii]tens.csv$', arquivo) is not None):\n","                with zip_ref.open(arquivo) as myfile:\n","                    lista_arquivos.append({'itens': BytesIO(myfile.read()),'nome_arquivo': arquivo})\n","\n","        arquivos = lista_arquivos\n","\n","    return arquivos\n"]},{"cell_type":"markdown","id":"67aa6074","metadata":{"id":"67aa6074"},"source":["#### <b>AGENTE 1: Aquisição de Documentos</b>\n","<b>Responsabilidade:</b> Obter e pré-processar documentos fiscais<br/><br/>\n","<b>Funcionalidades:</b>\n","<ul><li>Interface para upload manual de arquivos (PDF, imagens)</li></ul>\n","<ul><li>Integração com APIs de órgãos governamentais (SEFAZ)</li></ul>\n","<ul><li>Validação inicial de formato e integridade dos documentos</li></ul>\n","<ul><li>Organização e catalogação dos arquivos recebidos</li></ul>"]},{"cell_type":"code","execution_count":24,"id":"6b16247c","metadata":{"id":"6b16247c","executionInfo":{"status":"ok","timestamp":1750312612897,"user_tz":180,"elapsed":16,"user":{"displayName":"Antonio Dantas","userId":"09143204756506017123"}}},"outputs":[],"source":["def agente1(pergunta,engine, arquivo,llm):\n","\n","    print('\\nExecutando agente 1...')\n","\n","    # VALIDAÇÃO DE INTEGRIDADE -> UMA FORMA DE GARANTIR QUE OS ARQUIVOS ESTÃO NO FORMATO ZIP\n","    #arquivos_zipados = lista_arquivos_zipados(diretorio)\n","\n","    #if arquivos_zipados == \"SemArquivoZip\":\n","    #    return \"SemArquivoZip\"\n","\n","    # VALIDAÇÃO DE INTEGRIDADE -> UMA FORMA DE GARANTIR QUE O ARQUIVO DE CABECALHO E O DE ITENS EXISTEM\n","\n","    arquivos = unzip(arquivo)\n","\n","    if arquivos == \"SemArquivoCabecalho\":\n","        return \"SemArquivoCabecalho\"\n","    elif arquivos == \"SemArquivoItens\":\n","        return \"SemArquivoItens\"\n","\n","    # VALIDAÇÃO DE INTEGRIDADE -> IMPLEMENTAR PARA DETERMINAR SE O ARQUIVO REALMENTE É UM TIPO ZIP. NÃO FAZER PELA EXTENSÃO\n","    # FAZER\n","\n","    \"\"\"\n","        Utilizando a LLM para identificar se os campos e resigstros da base de documentos, é capaz de responder a pergunta\n","        do usuário.\n","\n","        Se sim, o arquivo é persistido no banco de dados, caso contrário, o arquivo é descartado.\n","    \"\"\"\n","    # FORMATANDO A SAÍDA DA LLM COM JsonOutputParser\n","    class Resposta(BaseModel):\n","        resposta: str = Field(description=\"Responda Sim ou Não\")\n","\n","    parseador = JsonOutputParser(pydantic_object=Resposta)\n","\n","    # CRIANDO O PROMPT PARA A LLM COM A SAIDA FORMATADA\n","    template = \"\"\"É possível responder a pergunta {pergunta} do usuário baseado no dataframe {df} ? {resposta}\"\"\"\n","\n","    prompt_template = PromptTemplate(\n","                                        template=template,\n","                                        input_variables=[\"pergunta\",\"df\"],\n","                                        partial_variables={\"resposta\" : parseador.get_format_instructions()}\n","                                    )\n","\n","    # CRIANDO A CADEIA DE EXECUÇÃO PARA A LLM\n","    chain = prompt_template | llm | parseador\n","\n","    # CATALOGANDO OS ARQUIVOS ZIPADOS NO BD\n","    j=0\n","\n","    inspector = sqlalc.inspect(engine)\n","\n","    #print('valor de j: ',j)\n","    for f in arquivos:\n","\n","        # SERÁ CRIADO UM DATAFRAME PARA CADA ARQUIVO\n","        if f.get('cabecalho') is not None:\n","            dfcabecalho = read_csv(f.get('cabecalho'))\n","\n","            # INSERINDO COLUNA COM O NOME DO ARQUIVO NO DATAFRAME\n","            dfcabecalho['ARQUIVO'] = f.get('nome_arquivo')\n","            df = dfcabecalho\n","\n","            #print('Dataframe de cabeçalho: ',df)\n","\n","            # INVOCANDO A LLM\n","            resposta = chain.invoke(input={\"pergunta\":pergunta, \"df\": df})['resposta']\n","\n","            if resposta == 'Sim':\n","                j+=1\n","\n","                print('Sim para o arquivo: ',f.get('nome_arquivo'))\n","\n","                # PRECISA VERIFICAR SE A TABELA JÁ EXISTE NO BANCO DE DADOS ANTES DE LER\n","                if 'NFCABECALHO' in inspector.get_table_names():\n","                    dftable = read_sql('NFCABECALHO', con=engine)\n","\n","                    #print('dftable NFCABECALHO\\n',dftable)\n","\n","                    # CUIDANDO DE DUPLICIDADE\n","                    df = df[~df['CHAVE DE ACESSO'].isin(dftable['CHAVE DE ACESSO'])]\n","\n","                # INSERINDO NO BANCO DE DADOS\n","                df.to_sql(name='NFCABECALHO', con=engine, if_exists='append', index=False)\n","\n","                continue\n","\n","            else:\n","                continue\n","\n","        if f.get('itens') is not None:\n","            dfitens = read_csv(f.get('itens'))\n","\n","            # INSERINDO COLUNA COM O NOME DO ARQUIVO NO DATAFRAME\n","            dfitens['ARQUIVO'] = f.get('nome_arquivo')\n","            df = dfitens\n","\n","            #print('Dataframe de itens: ',df)\n","\n","            # INVOCANDO A LLM\n","            resposta = chain.invoke(input={\"pergunta\":pergunta, \"df\": df})['resposta']\n","\n","            if resposta == 'Sim':\n","                j+=1\n","\n","                print('Sim para o arquivo: ',f.get('nome_arquivo'))\n","\n","                 # PRECISA VERIFICAR SE A TABELA JÁ EXISTE NO BANCO DE DADOS ANTES DE LER\n","                if 'NFITENS' in inspector.get_table_names():\n","                    dftable = read_sql('NFITENS', con=engine)\n","\n","                    #print('dftable NFINTENS\\n',dftable)\n","\n","                    # CUIDANDO DE DUPLICIDADE\n","                    df = df[~df['CHAVE DE ACESSO'].isin(dftable['CHAVE DE ACESSO'])]\n","\n","                # INSERINDO NO BANCO DE DADOS\n","                df.to_sql(name='NFITENS', con=engine, if_exists='append', index=False)\n","\n","                continue\n","\n","            else:\n","                continue\n","\n","    if j == 0:\n","        return \"Não\"\n","\n","    else:\n","        return \"Sim\""]},{"cell_type":"markdown","id":"5a37657e","metadata":{"id":"5a37657e"},"source":["#### <b>AGENTE 2: Extração e Aprendizado</b>\n","<b>Responsabilidade:</b> Processar documentos e extrair dados relevantes<br/><br/>\n","<b>Funcionalidades:</b>\n","<ul><li>OCR avançado para digitalização de documentos</li></ul>\n","<ul><li>NLP para identificação e extração de campos específicos</li></ul>\n","<ul><li>IA para adaptação a novos layouts</li></ul>\n","<ul><li>Validação cruzada de dados extraídos</li></ul>"]},{"cell_type":"code","execution_count":25,"id":"459bb873","metadata":{"id":"459bb873","executionInfo":{"status":"ok","timestamp":1750312612898,"user_tz":180,"elapsed":1,"user":{"displayName":"Antonio Dantas","userId":"09143204756506017123"}}},"outputs":[],"source":["def agente2(pergunta,llm,engine):\n","\n","    print('\\nExecutando agente 2...')\n","\n","    # FORMATANDO A SAÍDA DA LLM COM JsonOutputParser\n","    class Query(BaseModel):\n","        query: str = Field(description='Esta é a query com DISTINCT e o nome de cada colunas entre \"')\n","\n","    parseador = JsonOutputParser(pydantic_object=Query)\n","\n","    # CRIANDO O PROMPT PARA A LLM COM A SAIDA FORMATADA\n","    template = \"\"\"Qual query deve ser executada na tabela NFCABECALHO com as colunas {colunas_tab_cabecalho} ou tabela NFITENS com as colunas {colunas_tab_itens} para responder\n","    a pergunta {pergunta}? {formatacao_saida}\"\"\"\n","\n","    prompt_template = PromptTemplate(\n","                                        template=template,\n","                                        input_variables=[\"pergunta\",\"colunas_tab_cabecalho\",\"colunas_tab_itens\"],\n","                                        partial_variables={\"formatacao_saida\" : parseador.get_format_instructions()}\n","                                    )\n","\n","    # CRIANDO A CADEIA DE EXECUÇÃO PARA A LLM\n","    chain = prompt_template | llm | parseador\n","\n","    with engine.connect() as con:\n","        query1 = sqlalc.text('PRAGMA table_info(NFCABECALHO)')\n","        rs = con.execute(query1)\n","        rows = rs.fetchall()\n","        colunas_query1 = sorted([col[1] for col in rows])\n","        #print('Colunas query1: ', colunas_query1)\n","\n","        query2 = sqlalc.text('PRAGMA table_info(NFITENS)')\n","        rs = con.execute(query2)\n","        rows = rs.fetchall()\n","        colunas_query2 = sorted([col[1] for col in rows])\n","        #print('Colunas query2: ', colunas_query2)\n","\n","\n","    query = chain.invoke(input={\"pergunta\":pergunta, \"colunas_tab_cabecalho\":colunas_query1,\"colunas_tab_itens\":colunas_query2})['query']\n","\n","    print('\\nQuery: ',query)\n","\n","    resposta = query\n","\n","    return resposta"]},{"cell_type":"markdown","id":"e5a89a55","metadata":{"id":"e5a89a55"},"source":["#### <b>AGENTE 3: Resposta e Interação</b>\n","<b>Responsabilidade:</b> Interface inteligente com usuários<br/><br/>\n","<b>Funcionalidades:</b>\n","<ul><li>Integração com LLMs para consultas em linguagem natural.</li></ul>"]},{"cell_type":"code","execution_count":26,"id":"7fa552db","metadata":{"id":"7fa552db","executionInfo":{"status":"ok","timestamp":1750312612913,"user_tz":180,"elapsed":1,"user":{"displayName":"Antonio Dantas","userId":"09143204756506017123"}}},"outputs":[],"source":["def agente3(pergunta,arquivo):\n","\n","    if not exists('nfs_data.db'): # CRIAÇÃO DO BANCO DE DADOS PARA A PRIMEIRA EXECUÇÃO\n","        print('\\nCriando o banco de dados nfs_data...')\n","        DATABASE_URL = \"sqlite:///nfs_data.db\" # Define o nome do arquivo do banco de dados\n","        engine = sqlalc.create_engine(DATABASE_URL)\n","\n","    else:\n","        engine = sqlalc.create_engine(\"sqlite:///nfs_data.db\") # Conecta ao banco de dados existente\n","\n","\n","    # INTEGRAÇÃO COM A LLM\n","    load_dotenv() # CARREGANDO O ARQUIVO COM A API_KEY\n","\n","    llm = ChatGoogleGenerativeAI(\n","        model=\"gemini-2.0-flash\",  # ou \"gemini-2.0-pro\"\n","        temperature=0.5,\n","        google_api_key=getenv(\"GOOGLE_API_KEY\")\n","    )\n","\n","\n","    try:\n","            print('\\nExecutando agente 3...')\n","\n","            print('\\nPergunta: ',pergunta)\n","\n","            resposta = agente1(pergunta,engine,arquivo,llm) # A ENGINE NÃO É FECHADA AUTOMATICAMENTE, APENAS AS CONEXÕES QUANDO USADAS COM WITH\n","\n","            if resposta == \"Sim\":\n","                query = agente2(pergunta,llm,engine)\n","\n","                # # OBTENÇÃO DO RESULTADO DA QUERY\n","                with engine.connect() as con:\n","                        df = read_sql(query, con)\n","                        resposta = df\n","\n","            elif resposta == \"Não\":\n","                    raise SemResposta\n","\n","            # elif resposta == \"SemArquivoZip\":\n","            #     raise SemArquivoZip\n","\n","            elif resposta == \"SemArquivoCabecalho\":\n","                    raise SemArquivoCabecalho\n","\n","            elif resposta == \"SemArquivoItens\":\n","                    raise SemArquivoItens\n","\n","\n","    # EXECUÇÃO DAS EXCEÇÕES\n","    except SemArquivoCabecalho:\n","            resposta = \"SemArquivoCabecalho\"\n","            print('\\nResposta: ', resposta)\n","\n","    except SemArquivoItens:\n","            resposta = \"SemArquivoItens\"\n","\n","    # except SemArquivoZip:\n","    #     caminho_absoluto = abspath(diretorio)\n","    #     print(f'\\nNão há arquivos zipados no diretório {caminho_absoluto}!\\n')\n","\n","    except SemResposta:\n","            resposta = \"SemResposta\"\n","\n","    print(f'\\nResposta\\n,{resposta}')\n","\n","    return resposta"]},{"cell_type":"markdown","id":"76b31d0c","metadata":{"id":"76b31d0c"},"source":["#### <b>TESTANDO</b>"]},{"cell_type":"code","execution_count":28,"id":"9e76b144","metadata":{"id":"9e76b144","colab":{"base_uri":"https://localhost:8080/","height":499},"executionInfo":{"status":"error","timestamp":1750312633046,"user_tz":180,"elapsed":51,"user":{"displayName":"Antonio Dantas","userId":"09143204756506017123"}},"outputId":"d85eb33c-19ec-485e-a03e-f0bee924b3c7"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Criando o banco de dados nfs_data...\n","\n","Executando agente 3...\n","\n","Pergunta:  Qual é a descrição dos serviços e a natureza da operação da nf com número 2525 ?\n","\n","Executando agente 1...\n"]},{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/content/drive/MyDrive/202401_NFS.zip'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-28-884066672.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m      \u001b[0mpergunta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Qual é a descrição dos serviços e a natureza da operação da nf com número 2525 ?\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m      \u001b[0mresposta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magente3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpergunta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marquivo\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Chama a função principal com a pergunta e o diretório\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m      \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nResposta: \\n'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mresposta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-26-1871436955.py\u001b[0m in \u001b[0;36magente3\u001b[0;34m(pergunta, arquivo)\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nPergunta: '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpergunta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0mresposta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magente1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpergunta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0marquivo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mllm\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# A ENGINE NÃO É FECHADA AUTOMATICAMENTE, APENAS AS CONEXÕES QUANDO USADAS COM WITH\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresposta\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"Sim\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-24-1269027775.py\u001b[0m in \u001b[0;36magente1\u001b[0;34m(pergunta, engine, arquivo, llm)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# VALIDAÇÃO DE INTEGRIDADE -> UMA FORMA DE GARANTIR QUE O ARQUIVO DE CABECALHO E O DE ITENS EXISTEM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0marquivos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marquivo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0marquivos\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"SemArquivoCabecalho\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-23-749906423.py\u001b[0m in \u001b[0;36munzip\u001b[0;34m(arquivo)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m#for f in arquivos_zipados:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marquivo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mzip_ref\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;31m#zip_ref.extractall(f'{diretorio_destino}')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps, metadata_encoding)\u001b[0m\n\u001b[1;32m   1293\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1294\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1295\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilemode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1296\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1297\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mfilemode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodeDict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/202401_NFS.zip'"]}],"source":["if __name__ == \"__main__\":\n","\n","     #arquivo = \".\\\\202401_NFS - new.zip\"  # Diretório onde os arquivos zipados estão localizados\n","\n","     arquivo = \"/content/drive/MyDrive/202401_NFS.zip\"  # Diretório onde os arquivos zipados estão localizados\n","\n","#     # EXEMPLOS DE PERGUNTA PARA TESTE. ELAS DEVEM SER OBTIDAS DO FRONTEND\n","     pergunta = \"Qual é a chave de acesso da nota 3510129 ?\"\n","     pergunta = \"Quem descobriu o Brasil ?\"\n","     pergunta = \"Qual é a descrição dos serviços de nf com número 2525 ?\"\n","     pergunta = \"Qual é a descrição dos serviços e a natureza da operação da nf com número 2525 ?\"\n","\n","     resposta = agente3(pergunta, arquivo)  # Chama a função principal com a pergunta e o diretório\n","     print('\\nResposta: \\n',resposta)\n"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"agente_nfs","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.10"}},"nbformat":4,"nbformat_minor":5}