{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a3458f4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27212,
     "status": "ok",
     "timestamp": 1750214986132,
     "user": {
      "displayName": "Antonio Dantas",
      "userId": "09143204756506017123"
     },
     "user_tz": 180
    },
    "id": "6a3458f4",
    "outputId": "4c17ffe7-1c6b-4c45-ac52-a3413f2d141c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qqqr requirements.txt\n",
    "%pip install -qqq --upgrade jupyter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b23614",
   "metadata": {
    "id": "49b23614"
   },
   "source": [
    "#### IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3f5916e",
   "metadata": {
    "id": "d3f5916e"
   },
   "outputs": [],
   "source": [
    "from os import getenv, mkdir, listdir\n",
    "from io import BytesIO\n",
    "from shutil import rmtree\n",
    "from os.path import basename,exists\n",
    "from pathlib import Path\n",
    "from zipfile import ZipFile\n",
    "from re import search\n",
    "from pandas import read_csv, read_sql\n",
    "import sqlalchemy as sqlalc\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "class SemArquivoCabecalho(Exception):\n",
    "    pass\n",
    "\n",
    "class SemArquivoItens(Exception):\n",
    "    pass\n",
    "\n",
    "class SemArquivoZip(Exception):\n",
    "    pass\n",
    "\n",
    "class SemResposta(Exception):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea27b222",
   "metadata": {
    "id": "ea27b222"
   },
   "source": [
    "#### FUNÇÃO QUE DESCOMPACTA ARQUIVOS<br/>\n",
    "<ul><li>VERIFICA SE EXISTE OS ARQUIVOS DE CABEÇALHO E ITENS</li></ul>\n",
    "<ul><li>CASO ALGUM DELES NÃO EXISTA, É LANÇADA UMA EXCEÇÃO (Raise)</li></ul>\n",
    "<ul><li>É OBRIGATÓRIO QUE OS ARQUIVOS SEJAM CSVs E TENHAM \"CABECALHO\" E \"ITENS\" NO NOME</li></ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb6c4842",
   "metadata": {
    "id": "eb6c4842"
   },
   "outputs": [],
   "source": [
    "def unzip(arquivo):    \n",
    "\n",
    "\n",
    "    #for f in arquivos_zipados:\n",
    "    with ZipFile(arquivo, 'r') as zip_ref:\n",
    "        \n",
    "        #zip_ref.extractall(f'{diretorio_destino}')\n",
    "         \n",
    "        arquivos = zip_ref.namelist()\n",
    "        #arquivos = [f'{Path(diretorio_destino) / x}' for x in listdir(f'{diretorio_destino}')]\n",
    "\n",
    "        print(f'Arquivos descompactados: {arquivos}')\n",
    "           \n",
    "        # Check if any pattern matches\n",
    "        arquivocabecalhoencontrado = any(search(r'.*[Cc]abecalho.csv$', arquivo) for arquivo in arquivos)\n",
    "        arquivoitensencontrado = any(search(r'.*[Ii]tens.csv$', arquivo) for arquivo in arquivos)\n",
    "\n",
    "        if arquivocabecalhoencontrado == False:\n",
    "            return \"SemArquivoCabecalho\"\n",
    "\n",
    "        elif arquivoitensencontrado == False:\n",
    "            return \"SemArquivoItens\"\n",
    "        \n",
    "        lista_arquivos = []\n",
    "        \n",
    "        for arquivo in arquivos:\n",
    "            if (search(r'.*[Cc]abecalho.csv$', arquivo) is not None):\n",
    "                with zip_ref.open(arquivo) as myfile:\n",
    "                    # The resulting BytesIO object can be used anywhere a file-like object is expected, \n",
    "                    # but it operates entirely in memory, making it useful for temporary processing of \n",
    "                    # binary data (such as images, PDFs, or ZIP files) without writing to disk. \n",
    "                    # A common use case is when you need to manipulate or pass file data to \n",
    "                    # APIs or libraries that expect a file-like object(Método read_csv do pandas), but you want to avoid \n",
    "                    # filesystem I/O.\n",
    "                    lista_arquivos.append({'cabecalho': BytesIO(myfile.read()),'nome_arquivo': arquivo})\n",
    "                    \n",
    "            elif (search(r'.*[Ii]tens.csv$', arquivo) is not None):\n",
    "                with zip_ref.open(arquivo) as myfile:\n",
    "                    lista_arquivos.append({'itens': BytesIO(myfile.read()),'nome_arquivo': arquivo})\n",
    "                             \n",
    "        arquivos = lista_arquivos\n",
    "        \n",
    "    return arquivos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67aa6074",
   "metadata": {
    "id": "67aa6074"
   },
   "source": [
    "#### <b>AGENTE 1: Aquisição de Documentos</b>\n",
    "<b>Responsabilidade:</b> Obter e pré-processar documentos fiscais<br/><br/>\n",
    "<b>Funcionalidades:</b>\n",
    "<ul><li>Interface para upload manual de arquivos (PDF, imagens)</li></ul>\n",
    "<ul><li>Integração com APIs de órgãos governamentais (SEFAZ)</li></ul>\n",
    "<ul><li>Validação inicial de formato e integridade dos documentos</li></ul>\n",
    "<ul><li>Organização e catalogação dos arquivos recebidos (Armazenando em banco de dados, se os arquivos responderem a pergunta)</li></ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b16247c",
   "metadata": {
    "id": "6b16247c"
   },
   "outputs": [],
   "source": [
    "def agente1(pergunta,engine, arquivo,llm):\n",
    "\n",
    "    print('\\nExecutando agente 1...')\n",
    "\n",
    "    # VALIDAÇÃO DE INTEGRIDADE -> UMA FORMA DE GARANTIR QUE OS ARQUIVOS ESTÃO NO FORMATO ZIP\n",
    "    #arquivos_zipados = lista_arquivos_zipados(diretorio)\n",
    "\n",
    "    #if arquivos_zipados == \"SemArquivoZip\":\n",
    "    #    return \"SemArquivoZip\"\n",
    "\n",
    "    # VALIDAÇÃO DE INTEGRIDADE -> UMA FORMA DE GARANTIR QUE O ARQUIVO DE CABECALHO E O DE ITENS EXISTEM\n",
    "    arquivos = unzip(arquivo)\n",
    "\n",
    "    if arquivos == \"SemArquivoCabecalho\":\n",
    "        return \"SemArquivoCabecalho\"\n",
    "    elif arquivos == \"SemArquivoItens\":\n",
    "        return \"SemArquivoItens\"\n",
    "\n",
    "    # VALIDAÇÃO DE INTEGRIDADE -> IMPLEMENTAR PARA DETERMINAR SE O ARQUIVO REALMENTE É UM TIPO ZIP. NÃO FAZER PELA EXTENSÃO\n",
    "    # FAZER\n",
    "\n",
    "    \"\"\"\n",
    "        Utilizando a LLM para identificar se os campos e resigstros da base de documentos, é capaz de responder a pergunta\n",
    "        do usuário.\n",
    "\n",
    "        Se sim, o arquivo é persistido no banco de dados, caso contrário, o arquivo é descartado.\n",
    "    \"\"\"\n",
    "    # FORMATANDO A SAÍDA DA LLM COM JsonOutputParser\n",
    "    class Resposta(BaseModel):\n",
    "        resposta: str = Field(description=\"Responda Sim ou Não\")\n",
    "\n",
    "    parseador = JsonOutputParser(pydantic_object=Resposta)\n",
    "\n",
    "    # CRIANDO O PROMPT PARA A LLM COM A SAIDA FORMATADA\n",
    "    template = \"\"\"É possível responder a pergunta {pergunta} do usuário baseado no dataframe {df} ? {resposta}\"\"\"\n",
    "\n",
    "    prompt_template = PromptTemplate(\n",
    "                                        template=template,\n",
    "                                        input_variables=[\"pergunta\",\"df\"],\n",
    "                                        partial_variables={\"resposta\" : parseador.get_format_instructions()}\n",
    "                                    )\n",
    "\n",
    "    # CRIANDO A CADEIA DE EXECUÇÃO PARA A LLM\n",
    "    chain = prompt_template | llm | parseador\n",
    "\n",
    "    # CATALOGANDO OS ARQUIVOS ZIPADOS NO BD\n",
    "    j=0\n",
    "\n",
    "    inspector = sqlalc.inspect(engine)\n",
    "\n",
    "    #print('valor de j: ',j)\n",
    "    for f in arquivos:\n",
    "\n",
    "        # SERÁ CRIADO UM DATAFRAME PARA CADA ARQUIVO\n",
    "        if f.get('cabecalho') is not None:\n",
    "            dfcabecalho = read_csv(f.get('cabecalho'))\n",
    "\n",
    "            # INSERINDO COLUNA COM O NOME DO ARQUIVO NO DATAFRAME\n",
    "            dfcabecalho['ARQUIVO'] = f.get('nome_arquivo')\n",
    "            df = dfcabecalho\n",
    "\n",
    "            #print('Dataframe de cabeçalho: ',df)\n",
    "\n",
    "            # INVOCANDO A LLM\n",
    "            resposta = chain.invoke(input={\"pergunta\":pergunta, \"df\": df})['resposta']\n",
    "\n",
    "            if resposta == 'Sim':\n",
    "                j+=1\n",
    "\n",
    "                print('Sim para o arquivo: ',f.get('nome_arquivo'))\n",
    "\n",
    "                # PRECISA VERIFICAR SE A TABELA JÁ EXISTE NO BANCO DE DADOS ANTES DE LER\n",
    "                if 'NFCABECALHO' in inspector.get_table_names():\n",
    "                    dftable = read_sql('NFCABECALHO', con=engine)\n",
    "\n",
    "                    #print('dftable NFCABECALHO\\n',dftable)\n",
    "\n",
    "                    # CUIDANDO DE DUPLICIDADE\n",
    "                    df = df[~df['CHAVE DE ACESSO'].isin(dftable['CHAVE DE ACESSO'])]\n",
    "\n",
    "                # INSERINDO NO BANCO DE DADOS\n",
    "                df.to_sql(name='NFCABECALHO', con=engine, if_exists='append', index=False)\n",
    "\n",
    "                continue\n",
    "\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "        if f.get('itens') is not None:\n",
    "            dfitens = read_csv(f.get('itens'))\n",
    "\n",
    "            # INSERINDO COLUNA COM O NOME DO ARQUIVO NO DATAFRAME\n",
    "            dfitens['ARQUIVO'] = f.get('nome_arquivo')\n",
    "            df = dfitens\n",
    "\n",
    "            #print('Dataframe de itens: ',df)\n",
    "\n",
    "            # INVOCANDO A LLM\n",
    "            resposta = chain.invoke(input={\"pergunta\":pergunta, \"df\": df})['resposta']\n",
    "\n",
    "            if resposta == 'Sim':\n",
    "                j+=1\n",
    "\n",
    "                print('Sim para o arquivo: ',f.get('nome_arquivo'))\n",
    "\n",
    "                 # PRECISA VERIFICAR SE A TABELA JÁ EXISTE NO BANCO DE DADOS ANTES DE LER\n",
    "                if 'NFITENS' in inspector.get_table_names():\n",
    "                    dftable = read_sql('NFITENS', con=engine)\n",
    "\n",
    "                    #print('dftable NFINTENS\\n',dftable)\n",
    "\n",
    "                    # CUIDANDO DE DUPLICIDADE\n",
    "                    df = df[~df['CHAVE DE ACESSO'].isin(dftable['CHAVE DE ACESSO'])]\n",
    "\n",
    "                # INSERINDO NO BANCO DE DADOS\n",
    "                df.to_sql(name='NFITENS', con=engine, if_exists='append', index=False)\n",
    "\n",
    "                continue\n",
    "\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "    if j == 0:\n",
    "        return \"Não\"\n",
    "\n",
    "    else:\n",
    "        return \"Sim\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a37657e",
   "metadata": {
    "id": "5a37657e"
   },
   "source": [
    "#### <b>AGENTE 2: Extração e Aprendizado</b>\n",
    "<b>Responsabilidade:</b> Processar documentos e extrair dados relevantes<br/><br/>\n",
    "<b>Funcionalidades:</b>\n",
    "<ul><li>OCR avançado para digitalização de documentos</li></ul>\n",
    "<ul><li>NLP para identificação e extração de campos específicos</li></ul>\n",
    "<ul><li>IA para adaptação a novos layouts</li></ul>\n",
    "<ul><li>Validação cruzada de dados extraídos</li></ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459bb873",
   "metadata": {
    "id": "459bb873"
   },
   "outputs": [],
   "source": [
    "def agente2(pergunta,llm,engine):\n",
    "\n",
    "    print('\\nExecutando agente 2...')\n",
    "\n",
    "    # FORMATANDO A SAÍDA DA LLM COM JsonOutputParser\n",
    "    class Query(BaseModel):\n",
    "        query: str = Field(description='Esta é a query com DISTINCT e o nome de cada coluna entre \"')\n",
    "\n",
    "    parseador = JsonOutputParser(pydantic_object=Query)\n",
    "\n",
    "    # CRIANDO O PROMPT PARA A LLM COM A SAIDA FORMATADA\n",
    "    template = \"\"\"Qual query deve ser executada na tabela NFCABECALHO com as colunas {colunas_tab_cabecalho} ou tabela NFITENS com as colunas {colunas_tab_itens} para responder\n",
    "    a pergunta {pergunta}? {formatacao_saida}\"\"\"\n",
    "\n",
    "    prompt_template = PromptTemplate(\n",
    "                                        template=template,\n",
    "                                        input_variables=[\"pergunta\",\"colunas_tab_cabecalho\",\"colunas_tab_itens\"],\n",
    "                                        partial_variables={\"formatacao_saida\" : parseador.get_format_instructions()}\n",
    "                                    )\n",
    "\n",
    "    # CRIANDO A CADEIA DE EXECUÇÃO PARA A LLM\n",
    "    chain = prompt_template | llm | parseador\n",
    "\n",
    "    with engine.connect() as con:\n",
    "        query1 = sqlalc.text('PRAGMA table_info(NFCABECALHO)')\n",
    "        rs = con.execute(query1)\n",
    "        rows = rs.fetchall()\n",
    "        colunas_query1 = sorted([col[1] for col in rows])\n",
    "        #print('Colunas query1: ', colunas_query1)\n",
    "\n",
    "        query2 = sqlalc.text('PRAGMA table_info(NFITENS)')\n",
    "        rs = con.execute(query2)\n",
    "        rows = rs.fetchall()\n",
    "        colunas_query2 = sorted([col[1] for col in rows])\n",
    "        #print('Colunas query2: ', colunas_query2)\n",
    "\n",
    "\n",
    "    query = chain.invoke(input={\"pergunta\":pergunta, \"colunas_tab_cabecalho\":colunas_query1,\"colunas_tab_itens\":colunas_query2})['query']\n",
    "\n",
    "    print('\\nQuery: ',query)\n",
    "\n",
    "    resposta = query\n",
    "\n",
    "    return resposta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a89a55",
   "metadata": {
    "id": "e5a89a55"
   },
   "source": [
    "#### <b>AGENTE 3: Resposta e Interação</b>\n",
    "<b>Responsabilidade:</b> Interface inteligente com usuários<br/><br/>\n",
    "<b>Funcionalidades:</b>\n",
    "<ul><li>Integração com LLMs para consultas em linguagem natural.</li></ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7fa552db",
   "metadata": {
    "id": "7fa552db"
   },
   "outputs": [],
   "source": [
    "def agente3(pergunta,arquivo):\n",
    "\n",
    "    if not exists('nfs_data.db'): # CRIAÇÃO DO BANCO DE DADOS PARA A PRIMEIRA EXECUÇÃO\n",
    "        print('\\nCriando o banco de dados nfs_data...')\n",
    "        DATABASE_URL = \"sqlite:///nfs_data.db\" # Define o nome do arquivo do banco de dados\n",
    "        engine = sqlalc.create_engine(DATABASE_URL)\n",
    "\n",
    "    else:\n",
    "        engine = sqlalc.create_engine(\"sqlite:///nfs_data.db\") # Conecta ao banco de dados existente\n",
    "\n",
    "\n",
    "    # INTEGRAÇÃO COM A LLM\n",
    "    load_dotenv() # CARREGANDO O ARQUIVO COM A API_KEY\n",
    "\n",
    "    llm = ChatGoogleGenerativeAI(\n",
    "        model=\"gemini-2.0-flash\",  # ou \"gemini-2.0-pro\"\n",
    "        temperature=0.5,\n",
    "        google_api_key=getenv(\"GOOGLE_API_KEY\")\n",
    "    )\n",
    "\n",
    "\n",
    "    try:\n",
    "            print('\\nExecutando agente 3...')\n",
    "\n",
    "            print('\\nPergunta: ',pergunta)\n",
    "\n",
    "            resposta = agente1(pergunta,engine,arquivo,llm) # A ENGINE NÃO É FECHADA AUTOMATICAMENTE, APENAS AS CONEXÕES QUANDO USADAS COM WITH\n",
    "\n",
    "            if resposta == \"Sim\":\n",
    "                query = agente2(pergunta,llm,engine)\n",
    "\n",
    "                # # OBTENÇÃO DO RESULTADO DA QUERY\n",
    "                with engine.connect() as con:\n",
    "                        df = read_sql(query, con)\n",
    "                        resposta = df\n",
    "\n",
    "            elif resposta == \"Não\":\n",
    "                    raise SemResposta\n",
    "\n",
    "            # elif resposta == \"SemArquivoZip\":\n",
    "            #     raise SemArquivoZip\n",
    "\n",
    "            elif resposta == \"SemArquivoCabecalho\":\n",
    "                    raise SemArquivoCabecalho\n",
    "\n",
    "            elif resposta == \"SemArquivoItens\":\n",
    "                    raise SemArquivoItens\n",
    "\n",
    "\n",
    "    # EXECUÇÃO DAS EXCEÇÕES\n",
    "    except SemArquivoCabecalho:\n",
    "            resposta = \"SemArquivoCabecalho\"\n",
    "            print('\\nResposta: ', resposta)\n",
    "\n",
    "    except SemArquivoItens:\n",
    "            resposta = \"SemArquivoItens\"\n",
    "\n",
    "    # except SemArquivoZip:\n",
    "    #     caminho_absoluto = abspath(diretorio)\n",
    "    #     print(f'\\nNão há arquivos zipados no diretório {caminho_absoluto}!\\n')\n",
    "\n",
    "    except SemResposta:\n",
    "            resposta = \"SemResposta\"\n",
    "\n",
    "    #print('\\nResposta\\n',f'{resposta}')\n",
    "    \n",
    "    return resposta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b31d0c",
   "metadata": {
    "id": "76b31d0c"
   },
   "source": [
    "#### <b>TESTANDO</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e76b144",
   "metadata": {
    "id": "9e76b144"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Executando agente 3...\n",
      "\n",
      "Pergunta:  Qual é a descrição dos serviços e a natureza da operação da nf com número 2525 ?\n",
      "\n",
      "Executando agente 1...\n",
      "Arquivos descompactados: ['202401_NFs_Cabecalho.csv', '202401_NFs_Itens.csv']\n",
      "Sim para o arquivo:  202401_NFs_Cabecalho.csv\n",
      "Sim para o arquivo:  202401_NFs_Itens.csv\n",
      "\n",
      "Executando agente 2...\n",
      "\n",
      "Query:  SELECT DISTINCT \"DESCRIÇÃO DO PRODUTO/SERVIÇO\", \"NATUREZA DA OPERAÇÃO\" FROM NFITENS WHERE \"NÚMERO\" = '2525'\n",
      "\n",
      "Resposta: \n",
      "    DESCRIÇÃO DO PRODUTO/SERVIÇO                NATUREZA DA OPERAÇÃO\n",
      "0  LANTERNA TATERAL CARRETA LED  VENDA DE MERCADORIA FORA DO ESTADO\n",
      "1            CINEMATICO RODO-AR  VENDA DE MERCADORIA FORA DO ESTADO\n",
      "2  ESPIRAL NYLON CABINE AMARELO  VENDA DE MERCADORIA FORA DO ESTADO\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "     #arquivo = \".\\\\202401_NFS - new.zip\"  # Diretório onde os arquivos zipados estão localizados\n",
    "     \n",
    "     arquivo = \"202401_NFS.zip\"  # Diretório onde os arquivos zipados estão localizados\n",
    "     \n",
    "#    # EXEMPLOS DE PERGUNTA PARA TESTE. ELAS DEVEM SER OBTIDAS DO FRONTEND\n",
    "     pergunta = \"Qual é a chave de acesso da nota 3510129 ?\"\n",
    "     pergunta = \"Quem descobriu o Brasil ?\"\n",
    "     pergunta = \"Qual é a descrição dos serviços de nf com número 2525 ?\"\n",
    "     pergunta = \"Qual é a descrição dos serviços e a natureza da operação da nf com número 2525 ?\"\n",
    "\n",
    "     resposta = agente3(pergunta, arquivo)  # Chama a função principal com a pergunta e o diretório\n",
    "     print('\\nResposta: \\n',resposta)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "agente_nfs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
