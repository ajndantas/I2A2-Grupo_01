{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3458f4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27212,
     "status": "ok",
     "timestamp": 1750214986132,
     "user": {
      "displayName": "Antonio Dantas",
      "userId": "09143204756506017123"
     },
     "user_tz": 180
    },
    "id": "6a3458f4",
    "outputId": "4c17ffe7-1c6b-4c45-ac52-a3413f2d141c"
   },
   "outputs": [],
   "source": [
    "%pip install -qqqr requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b23614",
   "metadata": {
    "id": "49b23614"
   },
   "source": [
    "#### IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3f5916e",
   "metadata": {
    "id": "d3f5916e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\Meu Drive\\Cursos e Treinamentos\\Cientista de Dados\\Treinamento Python\\I2A2\\Desafios\\Desafio 2 - Projeto - 11062025\\agente_nfs\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from os import getenv\n",
    "from os.path import exists\n",
    "from pandas import read_csv, read_sql\n",
    "import sqlalchemy as sqlalc\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from magic import from_file\n",
    "\n",
    "class SemResposta(Exception):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67aa6074",
   "metadata": {
    "id": "67aa6074"
   },
   "source": [
    "#### <b>AGENTE 1: Aquisição de Documentos</b>\n",
    "<b>Responsabilidade:</b> Obter e pré-processar documentos fiscais<br/><br/>\n",
    "<b>Funcionalidades:</b>\n",
    "<ul><li>Interface para upload manual de arquivos (PDF, imagens)</li></ul>\n",
    "<ul><li>Integração com APIs de órgãos governamentais (SEFAZ)</li></ul>\n",
    "<ul><li>Validação inicial de formato e integridade dos documentos</li></ul>\n",
    "<ul><li>Organização e catalogação dos arquivos recebidos (Armazenando em banco de dados, se os arquivos responderem a pergunta)</li></ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b16247c",
   "metadata": {
    "id": "6b16247c"
   },
   "outputs": [],
   "source": [
    "def agente1(pergunta, engine, arquivo, llm):\n",
    "\n",
    "    lista_arquivos = []\n",
    "    lista_arquivos.append(arquivo)\n",
    "    \n",
    "    print('\\nExecutando agente 1...')\n",
    "\n",
    "    # VALIDAÇÃO DE INTEGRIDADE -> IMPLEMENTAR PARA DETERMINAR SE O ARQUIVO REALMENTE É UM TIPO ZIP. NÃO FAZER PELA EXTENSÃO\n",
    "    # FAZER\n",
    "\n",
    "    \"\"\"\n",
    "        Utilizando a LLM para identificar se os campos e registros da base de documentos, sãa capazes de responder a pergunta\n",
    "        do usuário.\n",
    "\n",
    "        Se sim, os arquivos são persistidos no banco de dados, caso contrário, o arquivo é descartado.\n",
    "    \"\"\"\n",
    "    # FORMATANDO A SAÍDA DA LLM COM JsonOutputParser\n",
    "    class Resposta(BaseModel):\n",
    "        resposta: str = Field(description=\"Responda Sim ou Não\")\n",
    "\n",
    "    parseador = JsonOutputParser(pydantic_object=Resposta)\n",
    "\n",
    "    # CRIANDO O PROMPT PARA A LLM COM A SAIDA FORMATADA\n",
    "    template = \"\"\"É possível responder a pergunta {pergunta} do usuário baseado no dataframe {df} ? {resposta}\"\"\"\n",
    "\n",
    "    prompt_template = PromptTemplate(\n",
    "                                        template=template,\n",
    "                                        input_variables=[\"pergunta\",\"df\"],\n",
    "                                        partial_variables={\"resposta\" : parseador.get_format_instructions()}\n",
    "                                    )\n",
    "\n",
    "    # CRIANDO A CADEIA DE EXECUÇÃO PARA A LLM\n",
    "    chain = prompt_template | llm | parseador\n",
    "\n",
    "    # CATALOGANDO OS ARQUIVOS NO BD\n",
    "    j=0\n",
    "\n",
    "    inspector = sqlalc.inspect(engine) # INSPECTOR PARA LISTAR AS TABELAS DO BANCO DE DADOS\n",
    "\n",
    "    for f in lista_arquivos:\n",
    "        \n",
    "        tipo = from_file(f, mime=True)\n",
    "        \n",
    "        \"\"\"\n",
    "            CSV -> text/plain\n",
    "            PDF -> application/pdf\n",
    "            PNG -> image/png\n",
    "        \"\"\"\n",
    "        print(f\"\\nArquivo: {f}, Tipo MIME detectado: {tipo}\")\n",
    "        \n",
    "        # ESTOU AQUI\n",
    "        if tipo != 'text/plain':\n",
    "            pass    \n",
    "            # SERÁ CRIADO UM DATAFRAME PARA CADA ARQUIVO\n",
    "        \n",
    "        df = read_csv(f)\n",
    "\n",
    "        # INSERINDO COLUNA COM O NOME DO ARQUIVO NO DATAFRAME\n",
    "        df['ARQUIVO'] = f         \n",
    "         \n",
    "        # INVOCANDO A LLM\n",
    "        resposta = chain.invoke(input={\"pergunta\":pergunta, \"df\": df})['resposta']\n",
    "\n",
    "        if resposta == 'Sim':\n",
    "                j+=1\n",
    "\n",
    "                print('Sim para o arquivo: ',f)\n",
    "\n",
    "                # PRECISA VERIFICAR SE A TABELA COM O NOME DO ARQUIVO JÁ EXISTE NO BANCO DE DADOS\n",
    "                if f in inspector.get_table_names():\n",
    "                    dftable = read_sql(f, con=engine)\n",
    "\n",
    "                    #print('dftable NFCABECALHO\\n',dftable)\n",
    "\n",
    "                    # CUIDANDO DE DUPLICIDADE\n",
    "                    df = df[~df['CHAVE DE ACESSO'].isin(dftable['CHAVE DE ACESSO'])]\n",
    "\n",
    "                # INSERINDO NO BANCO DE DADOS\n",
    "                df.to_sql(name=f, con=engine, if_exists='append', index=False)\n",
    "\n",
    "                continue\n",
    "\n",
    "        else:\n",
    "                continue\n",
    "\n",
    "\n",
    "    if j == 0:\n",
    "        return \"Não\"\n",
    "\n",
    "    else:\n",
    "        return \"Sim\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a37657e",
   "metadata": {
    "id": "5a37657e"
   },
   "source": [
    "#### <b>AGENTE 2: Extração e Aprendizado</b>\n",
    "<b>Responsabilidade:</b> Processar documentos e extrair dados relevantes<br/><br/>\n",
    "<b>Funcionalidades:</b>\n",
    "<ul><li>OCR avançado para digitalização de documentos</li></ul>\n",
    "<ul><li>NLP para identificação e extração de campos específicos</li></ul>\n",
    "<ul><li>IA para adaptação a novos layouts</li></ul>\n",
    "<ul><li>Validação cruzada de dados extraídos</li></ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "459bb873",
   "metadata": {
    "id": "459bb873"
   },
   "outputs": [],
   "source": [
    "def agente2(pergunta,llm,engine,arquivo):\n",
    "\n",
    "    print('\\nExecutando agente 2...')\n",
    "\n",
    "    # FORMATANDO A SAÍDA DA LLM COM JsonOutputParser\n",
    "    class Query(BaseModel):\n",
    "        query: str = Field(description='Esta é a query com DISTINCT aonde o nome de cada coluna e das tabelas devem ficar entre \"')\n",
    "\n",
    "    parseador = JsonOutputParser(pydantic_object=Query)\n",
    "\n",
    "    # CRIANDO O PROMPT PARA A LLM COM A SAIDA FORMATADA\n",
    "    template_query = \"\"\"Qual query deve ser executada na tabela {nome_arquivo} com as colunas {colunas} para responder\n",
    "    a pergunta {pergunta}? Se a query envolver as tabelas, deve ser feito um JOIN entre elas utlizando a coluna \"CHAVE DE ACESSO\" como chave. {formatacao_saida}\"\"\"\n",
    "\n",
    "    prompt_template_query = PromptTemplate(\n",
    "                                            template=template_query,\n",
    "                                            input_variables=[\"pergunta\",\"nome_arquivo\",\"colunas\"],\n",
    "                                            partial_variables={\"formatacao_saida\" : parseador.get_format_instructions()}\n",
    "                                          )\n",
    "\n",
    "    # CRIANDO A CADEIA DE EXECUÇÃO PARA A LLM\n",
    "    chain = prompt_template_query | llm | parseador\n",
    "\n",
    "    with engine.connect() as con:\n",
    "        query1 = sqlalc.text(f'PRAGMA table_info(\"{arquivo}\")')\n",
    "        rs = con.execute(query1)\n",
    "        rows = rs.fetchall()\n",
    "        colunas_query = sorted([col[1] for col in rows])\n",
    "        \n",
    "    query = chain.invoke(input={\"pergunta\":pergunta, \"nome_arquivo\":arquivo, \"colunas\":colunas_query})['query']\n",
    "\n",
    "    print('\\nQuery: ',query)\n",
    "\n",
    "    resposta = query\n",
    "\n",
    "    return resposta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a89a55",
   "metadata": {
    "id": "e5a89a55"
   },
   "source": [
    "#### <b>AGENTE 3: Resposta e Interação</b>\n",
    "<b>Responsabilidade:</b> Interface inteligente com usuários<br/><br/>\n",
    "<b>Funcionalidades:</b>\n",
    "<ul><li>Integração com LLMs para consultas em linguagem natural.</li></ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fa552db",
   "metadata": {
    "id": "7fa552db"
   },
   "outputs": [],
   "source": [
    "def agente3(pergunta,arquivo):\n",
    "\n",
    "    if not exists('nfs_data.db'): # CRIAÇÃO DO BANCO DE DADOS PARA A PRIMEIRA EXECUÇÃO\n",
    "        print('\\nCriando o banco de dados nfs_data...')\n",
    "        DATABASE_URL = \"sqlite:///nfs_data.db\" # Define o nome do arquivo do banco de dados\n",
    "        engine = sqlalc.create_engine(DATABASE_URL)\n",
    "\n",
    "    else:\n",
    "        engine = sqlalc.create_engine(\"sqlite:///nfs_data.db\") # Conecta ao banco de dados existente\n",
    "\n",
    "\n",
    "    # INTEGRAÇÃO COM A LLM\n",
    "    load_dotenv() # CARREGANDO O ARQUIVO COM A API_KEY\n",
    "\n",
    "    llm = ChatGoogleGenerativeAI(\n",
    "        model=\"gemini-2.5-flash\",  # ou \"gemini-2.0-pro\"\n",
    "        temperature=0.5,\n",
    "        google_api_key=getenv(\"GOOGLE_API_KEY\")\n",
    "    )\n",
    "\n",
    "\n",
    "    try:\n",
    "            print('\\nExecutando agente 3...')\n",
    "\n",
    "            print('\\nPergunta: ',pergunta)\n",
    "\n",
    "            resposta = agente1(pergunta,engine,arquivo,llm) # A ENGINE NÃO É FECHADA AUTOMATICAMENTE, APENAS AS CONEXÕES QUANDO USADAS COM WITH\n",
    "\n",
    "            if resposta == \"Sim\": # VERIFICA SE A LLM RESPONDEU SIM PARA ALGUM ARQUIVO, OU SEJA, SE É CAPAZ DE RESPONDER A PERGUNTA DO USUÁRIO COM OS\n",
    "                                  # ARQUIVOS FORNECIDOS\n",
    "                                  \n",
    "                query = agente2(pergunta,llm,engine,arquivo)\n",
    "\n",
    "                # # OBTENÇÃO DO RESULTADO DA QUERY\n",
    "                with engine.connect() as con:\n",
    "                        df = read_sql(query, con)\n",
    "                        resposta = df\n",
    "\n",
    "            elif resposta == \"Não\":\n",
    "                raise SemResposta\n",
    "\n",
    "    except SemResposta:\n",
    "            resposta = \"SemResposta\"\n",
    "\n",
    "    print('\\nResposta\\n',f'{resposta}')\n",
    "    \n",
    "    return resposta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b31d0c",
   "metadata": {
    "id": "76b31d0c"
   },
   "source": [
    "#### <b>TESTANDO</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e76b144",
   "metadata": {
    "id": "9e76b144"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Executando agente 3...\n",
      "\n",
      "Pergunta:  Qual é a chave de acesso da nota 3510129 ?\n",
      "\n",
      "Executando agente 1...\n",
      "\n",
      "Arquivo: nota_fiscal_exemplo.png, Tipo MIME detectado: image/png\n"
     ]
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mUnicodeDecodeError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     13\u001b[39m pergunta = \u001b[33m\"\u001b[39m\u001b[33mQual é a chave de acesso da nota 3510129 ?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m#pergunta = \"Quem descobriu o Brasil ?\"\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m#pergunta = \"Qual é a descrição dos serviços de nf com número 2525 ?\"\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m#pergunta = \"Qual é a descrição dos serviços e a natureza da operação da nf com número 2525 ?\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m resposta = \u001b[43magente3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpergunta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marquivo\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Chama a função principal com a pergunta e o diretório\u001b[39;00m\n\u001b[32m     19\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mResposta: \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m,resposta)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 27\u001b[39m, in \u001b[36magente3\u001b[39m\u001b[34m(pergunta, arquivo)\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mExecutando agente 3...\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     25\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mPergunta: \u001b[39m\u001b[33m'\u001b[39m,pergunta)\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m resposta = \u001b[43magente1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpergunta\u001b[49m\u001b[43m,\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\u001b[43marquivo\u001b[49m\u001b[43m,\u001b[49m\u001b[43mllm\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# A ENGINE NÃO É FECHADA AUTOMATICAMENTE, APENAS AS CONEXÕES QUANDO USADAS COM WITH\u001b[39;00m\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m resposta == \u001b[33m\"\u001b[39m\u001b[33mSim\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;66;03m# VERIFICA SE A LLM RESPONDEU SIM PARA ALGUM ARQUIVO, OU SEJA, SE É CAPAZ DE RESPONDER A PERGUNTA DO USUÁRIO COM OS\u001b[39;00m\n\u001b[32m     30\u001b[39m                       \u001b[38;5;66;03m# ARQUIVOS FORNECIDOS\u001b[39;00m\n\u001b[32m     32\u001b[39m     query = agente2(pergunta,llm,engine,arquivo)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 52\u001b[39m, in \u001b[36magente1\u001b[39m\u001b[34m(pergunta, engine, arquivo, llm)\u001b[39m\n\u001b[32m     49\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mArquivo: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, Tipo MIME detectado: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtipo\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     51\u001b[39m \u001b[38;5;66;03m# SERÁ CRIADO UM DATAFRAME PARA CADA ARQUIVO\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m df = \u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[38;5;66;03m# INSERINDO COLUNA COM O NOME DO ARQUIVO NO DATAFRAME\u001b[39;00m\n\u001b[32m     55\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mARQUIVO\u001b[39m\u001b[33m'\u001b[39m] = f         \n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\Meu Drive\\Cursos e Treinamentos\\Cientista de Dados\\Treinamento Python\\I2A2\\Desafios\\Desafio 2 - Projeto - 11062025\\agente_nfs\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\Meu Drive\\Cursos e Treinamentos\\Cientista de Dados\\Treinamento Python\\I2A2\\Desafios\\Desafio 2 - Projeto - 11062025\\agente_nfs\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\Meu Drive\\Cursos e Treinamentos\\Cientista de Dados\\Treinamento Python\\I2A2\\Desafios\\Desafio 2 - Projeto - 11062025\\agente_nfs\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\Meu Drive\\Cursos e Treinamentos\\Cientista de Dados\\Treinamento Python\\I2A2\\Desafios\\Desafio 2 - Projeto - 11062025\\agente_nfs\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1898\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1895\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[32m   1897\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1898\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1899\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1900\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\Meu Drive\\Cursos e Treinamentos\\Cientista de Dados\\Treinamento Python\\I2A2\\Desafios\\Desafio 2 - Projeto - 11062025\\agente_nfs\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:93\u001b[39m, in \u001b[36mCParserWrapper.__init__\u001b[39m\u001b[34m(self, src, **kwds)\u001b[39m\n\u001b[32m     90\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m kwds[\u001b[33m\"\u001b[39m\u001b[33mdtype_backend\u001b[39m\u001b[33m\"\u001b[39m] == \u001b[33m\"\u001b[39m\u001b[33mpyarrow\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     91\u001b[39m     \u001b[38;5;66;03m# Fail here loudly instead of in cython after reading\u001b[39;00m\n\u001b[32m     92\u001b[39m     import_optional_dependency(\u001b[33m\"\u001b[39m\u001b[33mpyarrow\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m \u001b[38;5;28mself\u001b[39m._reader = \u001b[43mparsers\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTextReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     95\u001b[39m \u001b[38;5;28mself\u001b[39m.unnamed_cols = \u001b[38;5;28mself\u001b[39m._reader.unnamed_cols\n\u001b[32m     97\u001b[39m \u001b[38;5;66;03m# error: Cannot determine type of 'names'\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:574\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader.__cinit__\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:663\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._get_header\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:874\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:891\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:2053\u001b[39m, in \u001b[36mpandas._libs.parsers.raise_parser_error\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen codecs>:322\u001b[39m, in \u001b[36mdecode\u001b[39m\u001b[34m(self, input, final)\u001b[39m\n",
      "\u001b[31mUnicodeDecodeError\u001b[39m: 'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "     #arquivo = \".\\\\202401_NFS - new.zip\"\n",
    "     \n",
    "     # TESTANDO OS TIPOS DE ARQUIVO\n",
    "     arquivo = \"202401_NFs_Cabecalho.csv\"\n",
    "     arquivo = \"Grupo_01_Proposta_de_Projeto.pdf\"\n",
    "     arquivo = \"nota_fiscal_exemplo.png\"\n",
    "     \n",
    "     #print('Diretório atual: ',getcwd())\n",
    "     \n",
    "#    # EXEMPLOS DE PERGUNTA PARA TESTE. ELAS DEVEM SER OBTIDAS DO FRONTEND\n",
    "     pergunta = \"Qual é a chave de acesso da nota 3510129 ?\"\n",
    "     #pergunta = \"Quem descobriu o Brasil ?\"\n",
    "     #pergunta = \"Qual é a descrição dos serviços de nf com número 2525 ?\"\n",
    "     #pergunta = \"Qual é a descrição dos serviços e a natureza da operação da nf com número 2525 ?\"\n",
    "\n",
    "     resposta = agente3(pergunta, arquivo)  # Chama a função principal com a pergunta e o diretório\n",
    "     print('\\nResposta: \\n',resposta)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "agente_nfs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
